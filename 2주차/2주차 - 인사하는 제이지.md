# 3장 시스테 설계 면접 공략법
## 시스템 설계 면접
* 단순한 기술적 평가 이상의 의미를 가짐
### 설계 면접에서 평가받는 것
* 설계 기술력
* 커뮤니케이션 능력
* 주도력
* 직무 적합성
* 문제해결력
### 부정적 시그널(red signal)
* 설계의 순수성에 집착
  * 오버 엔지니어링으로 시스템 전반의 비용을 높일 가능성이 존재
* 완고함
  * 트레이드오프를 따져 타협을 할 줄 알아야 함 
* 편협함

## 효과적 면접을 위한 4단계 접근법
### 1단계 문제 이해 및 설계 범위 확정
* 빠르게 답을 내려고 하지 마라
* 깊이 생각하고 질문하여 요구사항과 가정을 명확히 하라
#### 질문 예시
* 구체적으로 어떤 기능들을 만들어야 하나?
* 제품 사용자 수는 얼마나 되나?
* 회사의 규모는 얼마나 빨리 커지리라 예상하나?
* 회사가 주로 사용하는 기술 스택은 무엇인가?
* 설계를 단순화하기 위해 활용할 수 있는 기존 서비스로는 어떤 것들이 있는가?
### 2단계 개략적인 설계안 제시 및 동의 구하기
* 설계안에 대한 최초 청사진을 제시하고 의견을 구하라.
  * 면접관을 마치 팀원인 것처럼 대하라
* 화이트보드나 종이에 핵심 컴포넌트를 포함하는 다이어그램을 그려라.
* 최초 설계안이 시스템 구모에 관계된 제약사항들을 만족하는지 개략적으로 계산해 보라
* 미처 고려하지 못한 에지 케이스 생각해보기
### 3단계 상세 설계
* 시스템 전반적으로 달성해야 할 목표와 기능 범위 확인
* 전체 설계의 개략적 청사진 마련
* 해당 청사진에 대한 면접관의 의견 청취
* 상세 설계에서 집중해야 할 영역들 확인
#### 집중해야 할 영역 예시
* 단축 URL 생성기 -> 해시 함수 설계 영역
* 채팅 시스템 -> 어떻게 지연시간을 줄이고, 사용자의 온/오프라인 상태를 표시할 것인가?
#### 불필요한 세부 사항 예시
* 페이스북 뉴스 피드 -> 순위를 매기는 EdgeRank 알고리즘 설명
  * 시간을 너무 많이 사용하게 되며, 면접 목적과 부합하지 않는 소재
### 4단계 마무리
* 면접관이 시스템 병목구간, 혹은 좀 더 개선 가능한 지점을 찾아내라 주문할 수 있다.
* 설계를 다시 한번 요약해주는 것이 도움이 될 수 있다.
* 오류가 발생하면 무슨 일이 생기는지 따져보면 흥미로울 것이다.
* 운영 이슈도 논의할 가치가 충분하다.
* 미래에 닥칠 규모 확장 요구에 어떻게 대처할 것인지도 흥미로운 주제다.
* 시간이 좀 남았다면, 필요하지만 다루지 못했던 세부적 개선사항들을 제안할 수 있다.
### 해야 할 것
* 질문을 통해 확인하라
* 문제의 요구사항을 이해하라
* 정답이나 최선의 답안은 없다는 것을 명심하라
* 면접관이 여러분의 사고 흐름을 이해할 수 있도록 하라
* 가능하다면 여러 해법을 제시하라
* 개략적 설계에 면접관이 동의하면, 각 컴포넌트의 세부사항을 설명하기 시작하라
* 면접관의 아이디어를 이끌어 내라
* 포기하지 말라
### 하지 말아야 할 것
* 전형적인 면접 문제들에도 대비하지 않은 상태에서 면접장에 가지 마라
* 요구사항이나 가정들을 분명히 하지 않은 상태에서 설계를 제시하지 마라
* 처음부터 특정 컴포넌트의 세부사항을 너무 깊이 설명하지 마라
* 진행 중에 막혔다면, 힌트를 청하기를 주저하지 마라
* 침묵 속에 설계를 진행하지 마라
* 설계안을 내놓는 순간 면접이 끝난다고 생각하지 마라.
* 의견을 일찍, 자주 구하라


# 4장 처리율 제한 장치의 설계
## rate limiter
* 네트워크 시스템에서 트래픽의 처리율을 제어하기 위한 장치
* HTTP를 예로 들면 특정 기간 내에 전송되는 클라이언트의 요청 횟수를 제한한다.
  * API 요청 횟수가 제한 장치에 정의된 임계치(threshold)를 넘어서면 추가로 도달한 모든 호출은 중단된다.
### rate limiter 장점
* DDoS 공격에 의한 자원 고갈을 방지할 수 있다.
  * 트위터는 3시간 동안 300개의 트윗만 올릴 수 있도록 제한하고 있다.
  * 구글 독스 API는 사용자당 분당 300회의 read 요청만 허용한다.
* 비용을 절감한다.
  * 요청을 받아주기 위해 많은 서버를 추가하지 않아도 된다.
  * 우선순위가 높은 API에 더 많은 자원을 할당할 수 있음
  * 서드 파티 API 사용료가 초과되는 것을 방지할 수 있음
* 서버 과부하를 막는다.
## 1단계 문제 이해 및 설계 범위 확정
### 가상 요구사항
* 설정된 처리율을 초과하는 요청을 정확하게 제한
* 낮은 응답시간: HTTP 응답시간에 악영향을 주어서는 안 된다.
* 가능한 적은 메모리 사용
* 분산 서버에서 사용되어야 함
* 예외 처리: 요청이 제한되면 그 사실을 사용자가 인지할 수 있도록 노출되어야 함
* 높은 내결함성
## 2단계 개략적 설계안 제시 및 동의 구하기
### 처리율 제한 장치는 어디에 둘 것인가?
* 클라이언트에 둔다면: 클라이언트 요청은 쉽게 위변조가 가능해서 rate limiter를 둘 장소가 못 됨
* 서버에 둔다면
  * API 서버단에 두기
  * 미들웨어로 API 서버에 진입하기 전에 제한
* 마이크로서비스의 경우
  * 일반적으로 API 게이트웨이에서 처리율을 제한함
### 처리율 제한 장치 위치를 선정할 때 고려해야 할 사항
* 프로그래밍 언어, 캐시 서비스 등 현재 사용하고 있는 기술 스택 점검
  * 사용하는 언어가 서버 측 구현을 지원하기 충분할 정도로 효율이 높은지 확인 필요
* 사업 필요에 맞는 알고리즘 선택
  * 직접 구현할 경우 제한없이 자유롭게 알고리즘을 선택할 수 있을 수 있음
* 이미 마이크로서비스 구조이거나 API 게이트웨이를 사용하고 있다면, 게이트웨이에서 rate limiter를 제공하는게 합리적
* 직접 구현 비용이 클 것 같다면 이미 rate limiter가 구현된 API 게이트웨이를 사용하는 것이 합리적일 수 있다.

![rate limiter](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6br81XOzOqr-aeDqRm4Vig.png)
### 처리율 제한 알고리즘
#### 토큰 버킷 알고리즘(token bucket)
![토큰 버킷](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w73RiyDJm0AFZ65M9XyB_A.png)

* 토큰 버킷은 지정된 용량을 갖는 컨테이너
* 사전 설정된 양의 토큰이 주기적으로 채워지고, 꽉 찬 버킷은 더 이상 토큰이 추가되지 않음
* 각 요청은 처리될 때마다 하나의 토큰을 사용하게 되고, 토큰이 없는 경우 해당 요청은 버려짐
* `버킷 크기`와 `토큰 공급률`이라는 2개의 인자가 존재함
* 통상적으로 API 엔드포인트마다 별도의 버킷을 둔다.
* IP 주소별로 처리율 제한을 적용해야 한다면 IP 주소마다 버킷을 하나씩 할당해야 함
##### 장점
* 구현이 쉽다.
* 메모리 사용 측면에서도 효율적
* 짧은 시간에 집중되는 트래픽(burst of traffic)도 처리 가능
##### 단점
* 버킷 크기와 토큰 공급률이라는 두 개의 인자를 적절하게 튜닝하는 것이 까다로움
#### 누출 버킷 알고리즘(leaky bucket)
![누출 버킷](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_41fVicfJ4EEitXWFiFKbA.png)

* 토큰 버킷과 달리 요청 처리율이 고정되어 있음
* FIFO로 구현됨. 큐가 가득 차 있으면 새 요청이 버려지고, 지정된 시간마다 큐에서 요청을 꺼내서 처리함
* `버킷 크기`와 `처리율` 이라는 2개의 인자가 존재함
##### 장점
* 메모리 사용량 측면에서 효율적
* 고정된 처리율을 갖고 있기 때문에 안정적 출력이 필요한 경우 적합하다.
##### 단점
* 버스트한 트래픽이 생길 경우 요청들이 제때 처리되지 못하면 최신 요청들이 버려짐
* 두 개의 인자를 적절하게 튜닝하는 것이 까다로움
#### 고정 윈도 카운터(fixed window counter)
![고정 윈도 카운터](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EdG-thC8YV5khwiWGo-X-Q.png)

* 타임라인을 고정된 간격의 윈도로 나누고, 각 윈도마다 카운터를 붙인다.
* 요청이 접수될 때마다 카운터의 값은 1씩 증가
* 카운터 값이 임계치에 도달하면 새로운 요청은 새 윈도가 열릴 때까지 버려짐
##### 장점
* 메모리 효율이 좋음
* 이해하기 쉬움
* 윈도가 닫히는 시점에 카운터를 초기화하는방식은 특정한 트래픽 패턴을 처리하기에 적합하다.
##### 단점
* 윈도 경계 부근에 일시적으로 트래픽이 몰리면 기대했던 시스템의 처리 한도보다 많은 양의 요청을 처리하게 된다. (TPS적 관점)
#### 이동 윈도 로그(sliding window log)
![이동 윈도 로그](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iFTxHuF1azrOB8VbV0M2Dw.png)
* 고정 윈도 카운터의 단점을 보완할 수 있는 방식
* 요청의 타임스탬프를 레디스의 정렬집합 같은 캐시에 보관해서 추적
* 새 요청이 오면 만료된 타임스탬프를 제거하고, 새 요청의 타임스탬프를 로그에 추가
  * 만료된 타임스탬프는 현재 윈도의 시작 시점보다 오래된 타임 스탬프
  * 새 요청의 타임스탬프 값이 윈도의 끝부분임
* 로그의 크기가 허용치보다 같거나 작으면 요청을 시스템에 전달하고 그렇지 않으면 처리 거부
##### 장점
* 매우 정확하게 처리율 제한을 수행할 수 있음
  * 어느 순간의 윈도를 보더라도 허용되는 요청의 개수는 시스템의 처리율 한도를 넘지 않음
##### 단점
* 거부된 요청의 타임스탬프도 보관하기 때문에 다량의 메모리를 사용하게 됨
#### 이동 윈도 카운터(sliding window counter)
![이동 윈도 카운터](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*js-77Ra-5xS-VVcVFlhdpw.png)
* 고정 윈도 카운터와 이동 윈도 카운터 기법을 결합한 알고리즘
* 현재 윈도우의 요청 수와 이전 윈도우의 요청 수에 가중치를 두어서 계산한 값을 요청량으로 사용함
##### 장점
* 이전 시간대의 평균 처리율에 따라 현재 윈도의 상태를 계산하므로 짧은 시간에 몰리는 트래픽에도 잘 대응한다.
* 메모리 효율이 좋다.
##### 단점
* 직전 시간대에 도착한 요청이 균등하게 분포되어 있다고 가정한 상태에서 추정치를 계산하기 때문에 다소 느슨하다.
  * 실험 기록에 따르면 실제 상태와 맞기 않게 허용되거나 버려진 요청의 비율이 0.003%에 불과했다고 함
### 개략적인 아키텍처
* 카운터 데이터는 어디에 보관할 것인가?
  * 데이터베이스는 디스크 IO 때문에 느려서 사용하기 힘듬
  * 레디스같은 메모리기반 저장소가 적절함
    * 메모리상에서 동작하는 캐시가 빠르고, 만료 정책을 지원하기 때문
    * 레디스는 INCR(메모리에 저장된 카운터의 값을 1 증가), EXPIRE(카운터에 타임아웃 값 설정) 명령어를 지원함
## 3단계 상세 설계
* 처리율 제한 규칙은 어떻게 만들어지고 어디에 저장되는가?
* 처리가 제한된 요청들은 어떻게 처리되는가?
### 처리율 제한 규칙
* 보통 이런 규칙들은 설정 파일 형태로 디스크에 저장함
* 코드에 명시하면 설정 변경이 필요할 때마다 코드 레벨에서 변경이 필요해지기 때문에 분리하는 것이 용이함
### 처리율 한도 초과 트래픽의 처리
* 어떤 요청이 한도 제한에 걸리면 API는 429 응답을 내보냄
* 경우에 따라 나중에 처리하기 위해 큐에 보관할 수도 있음
#### 처리율 제한 장치가 사용하는 HTTP 헤더
* 클라이언트는 자기 요청이 처리율 제한에 걸리고 있는지를 어떻게 감지할 수 있나?
  * custom 응답 헤더를 통해서 현재 rate limiter 상태를 알려주는 방법이 있을 수 있음

### 상세 설계 결과물
![rate limiter 아키텍처](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h70PQKa_ehiZAoUHFXhJkg.png)

### 분산 환경에서의 처리율 제한 장치의 구현
#### 경쟁 조건
* 예시: 여러 스레드가 레디스에서 동시에 읽은 동일한 값을 counter + 1을 해서 덮어씌우려는 경우

![경쟁 조건](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*all1QUICSpltt0PCRAxxAQ.png)
##### 해결책
* 분산락
  * 성능 저하
* 레디스 커스터마이징
  * 책 번역이 이상한 것 같고, 참고문헌이 잘못되어 있음(루아는 언어 중 하나)
  * https://medium.com/@lordmoma/race-condition-solution-no-locks-for-rate-limiting-with-redis-bac0f071872e
* 레디스의 정렬 집합 자료 구조 사용

#### 동기화 이슈
##### 해결책
* sticky session
  * 부하가 심해질 수 있고, 확장성이 떨어짐
* session clustering
  * 각 서버 데이터의 동기화가 유지되어야 하고, 메모리가 많이 듬
* session storage 
#### 성능 최적화
* 사용자의 트래픽을 가장 가까운 에지 서버로 전달하여야 함
* 제한 장치 간에 데이터를 동기화할 때 최종 일관성 모델을 사용해야 함 
  * 낙관적 락을 의미하는 듯
#### 모니터링
* 모니터링을 통해 다음을 확인하고자 함
  * 채택된 처리율 제한 알고리즘이 효과적인지
  * 정의한 처리율 제한 규칙이 효과적인지
## 4단계 마무리
### 면접 마무리에 언급해보면 좋을 주제
* hard vs soft: 요청 개수가 임계치를 절대 넘어갈 수 없는지 잠시 동안은 넘어설 수 있는지
* 다양한 계층에서의 처리율 제한
  * HTTP
  * Iptables
* 처리율 제한을 회피하는 방법. 클라이언트는 어떻게 설계하는 것이 최선인가?
  * 클라이언트 측 캐시를 사용하여 API 호출 횟수 최소화
  * rate limit 스펙을 인지하여 조심해서 API 호출
  * 클라이언트는 예외 처리 로직을 통해서 graceful하게 복구할 수 있도록 한다.
  * 재시도 로직을 구현할 때 충분한 back-off 시간을 둔다.

## 그림 출처
https://medium.com/geekculture/system-design-design-a-rate-limiter-81d200c9d392
https://levelup.gitconnected.com/top-5-rate-limiting-tactics-for-optimal-traffic-5ea77fd4461c