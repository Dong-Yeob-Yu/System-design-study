# 3장. 시스템 설계 면접 공략법

## 효과적 면접을 위한 4단계 접근법

### 1. 문제 이해 및 설계 범위 확정

- 생각없이 바로 답부터 말하지 말고 깊이 생각하고 질문하여 요구사항과 가정들을 분명히 하라
- 요구사항을 정확히 이해하는 데 필요한 질문을 하라
    - 요구사항을 이해하고 모호함을 없애는 게 이 단계에서 가장 중요하다.

### 2. 개략적인 설계안 제시 및 동의 구하기

- 이 과정은 면접관과 협력하며 진행하는 것이 좋다.
    
    → 최초 청사진을 제시하고 의견을 구하기 (면접관을 마치 팀원인 것처럼)
    
- 핵심 컴포넌트를 포함하는 다이어그램을 그리기
- 최초 설계안이 시스템 규모에 관계된 제약사항들을 만족하는지를 개략적으로 계산하기

### 3. 상세 설계

- 설계 대상 컴포넌트 사이의 우선순위를 정하기
    - 불필요한 세부사항에 시간을 쓰지 말라
- 대부분의 면접관들은 특정 시스템 컴포넌트들의 세부사항을 깊이 있게 설명하는 것을 보기 원함

### 4. 마무리

- 나의 설계에서 병목구간 또는 더 개선 가능한 지점 찾아내기
- 내가 만든 설계를 다시 한번 요약 → 면접관의 기억을 환기시켜주는 효과
- 미래의 규모 확장에 대한 대처나 다루지 못했던 세부적 개선사항들을 제안하는 것도 좋음

## 면접 세션에서 To do와 Not To do

### To do

- 질문을 통해 확인하기 → 문제의 요구사항을 이해하기
- 정답이나 최선의 답안 같은 것은 없다는 것을 명심
- 면접관이 나의 사고흐름을 이해할 수 있도록 하기 → “소통”하기 (면접관의 아이디어를 끌어내기)
- 가능하면 여러 해법을 함께 제시하기

### Not to do

- 전형적인 면접 문제들에도 대비하지 않은 상태에서 면접장에 가지 않기
- 요구사항이나 가정들을 분명히 하지 않은 상태에서 설계를 제시하지 않기
- 개략적인 설계를 마친 후에 세부사항으로 나아가기
- 힌트 청하기를 주저하지 말기 (침묵 속에서 설계를 진행하지 말기)
- 의견을 일찍 그리고 자주 구하기 (면접관이 끝났다고 말하기 전까지 끝난게 아니다)

<br><br>

# 4장. 처리율 제한 장치의 설계

처리량 제한 장치는 클라이언트 또는 서비스가 보내는 트래픽의 처리율을 제어하기 위한 장치이다. 요청 수가 임계치를 넘어서면 추가로 도달한 모든 호출은 처리가 중단(block)된다.

## 처리량 제한 장치의 이점

### DoS 공격에 의한 자원 고갈 방지

처리율 제한 장치를 두면 추가 요청에 대해서는 처리를 중단하기 때문에 DoS 공격을 방지한다.

### 비용 절감

추가 요청에 대한 처리를 제한하면 서버를 많이 두지 않아도 되고, 우선순위가 높은 API에 더 많은 자원을 할당할 수 있다. 또한 제3자(third-party) API에 사용료를 지불하고 있는 회사라면, 그 호출 횟수를 제한할 수 있기 때문에 비용을 절감할 수 있다.

### 서버 과부하를 막는다

봇(bot)에서 오는 트래픽이나 사용자의 잘못된 이용 패턴으로 유발된 트래픽을 걸러내는데 처리율 제한 장치를 활용할 수 있다.

## 처리율 제한 장치의 위치

클라이언트는 일반적으로 처리율 제한을 안정적으로 걸 수 있는 장소가 되지 못한다. 클라이언트 요청은 쉽게 위변조가 가능하기 때문이다. 또한 모든 클라이언트의 구현을 통제하는 것도 어려울 수 있다. 때문에 서버 측에 두거나 처리율 제한 미들웨어를 만들어 해당 미들웨어로 하여금 API 서버로 가는 요청을 통제하도록 할 수 있다. 

클라우드 마이크로서비스의 경우, 일반적으로 처리율 제한 장치를 API 게이트웨이(Gateway)라 불리는 컴포넌트에 구현된다. 

> API 게이트웨이란?
처리율 제한, SSL 종단, 사용자 인증, IP 허용 목록 관리 등을 지원하는 완전 위탁 관리형 서비스, 즉 클라우드 업체가 유지 보수를 담당하는 서비스다.
> 

## 처리율 제한 알고리즘

서버 측에서 모든 것을 구현하기로 했다면, 알고리즘은 자유롭게 선택할 수 있다. 널리 알려진 인기 알고리즘으로는 다음과 같다.

### 토큰 버킷 알고리즘

토큰 버킷은 지정된 용량을 갖는 컨테이너다. 이 버킷에는 사전 설정된 양의 토큰이 주기적으로 채워지며 토큰이 가득 찬 버킷에는 더 이상의 토큰은 추가되지 않고 버려진다. 이 토큰 버킷 알고리즘은 버킷 크기와 토큰 공급률, 이렇게 2개의 인자를 받는다.

각 요청은 처리될 때마다 하나의 토큰을 사용한다. 요청이 도착하면 버킷에 충분한 토큰이 있는지 검사하고, 충분한 토큰이 있는 경우, 버킷에서 토큰 하나를 꺼낸 후 요청을 시스템에 전달한다. 만약 충분한 토큰이 없다면 해당 요청은 버려지게 된다. 

버킷의 개수는 공급 제한 규칙에 따라 달라진다. 통상적으로 API 엔드포인트마다 별도의 버킷을 두지만 만약 IP 주소별로 처리율 제한을 적용해야 한다면 IP 주소마다 버킷을 하나씩 할당할 수도 있다.

**장점**

- 구현이 쉽다
- 메모리 사용 측면에서도 효율적이다
- 짧은 시간에 집중되는 트래픽도 처리 가능하다.

**단점**

- 버킷 크기와 토큰 공급률이라는 2개의 인자를 적절하게 튜닝하는 것이 까다롭다.

### 누출 버킷 알고리즘

토큰 버킷 알고리즘과 비슷하지만 요청 처리율이 고정되어 있다는 점이 다르다. 보통 FIFO 큐로 구현하는데 동작원리는 다음과 같다. 요청이 도착하면 큐가 가득 차 있는지 보고 빈자리가 있을 경우에만 큐에 요청을 추가한다. 즉, 큐가 가득 차 있는 경우에 요청이 새로 들어오면 해당 요청은 버려진다. 지정된 시간마다 큐에서 요청을 꺼내서 처리한다. 누출 버킷 알고리즘은 버킷 크기와 처리율, 이렇게 2개의 인자를 사용한다.

**장점**

- 큐의 크기가 제한되어 있어 메모리 사용량 측면에서 효율적이다
- 고정된 처리율을 가지고 있기 때문에 안정적 출력이 필요한 경우에 적합하다.

**단점**

- 단시간에 많은 트래픽이 몰리는 경우, 최신 요청들이 버려진다. (오래된 요청들만 쌓임)
- 2개의 인자를 적절하게 튜닝하는 것이 까다롭다.

### 고정 윈도우 카운터 알고리즘

타임라인을 고정된 윈도(window)로 나누고, 각 윈도마다 카운터(counter)를 붙인다. 요청이 접수될 때마다 이 카운터의 값은 1씩 증가하고 이 카운터의 값이 설정된 임계치(threshold)에 도달하면 새로운 요청은 새 윈도가 열릴 때까지 버려진다.

이 알고리즘의 가장 큰 문제는 윈도의 경계 부근에 순간적으로 많은 트래픽이 집중될 경우, 윈도에 할당된 양보다 더 많은 요청이 처리될 수 있다는 문제점이 존재한다.

**장점**

- 메모리 효율이 좋다.
- 윈도가 닫히는 시점에 카운터를 초기화하는 방식은 특정한 트래픽 패턴을 처리하기에 적합하다.

**단점**

- 윈도 경계 부근에서 많은 트래픽이 몰려들 경우, 기대했던 시스템의 처리 한도보다 많은 양의 요청을 처리하게 된다.

### 이동 윈도우 로깅 알고리즘

고정 윈도 카운터 알고리즘의 문제를 해결하는 방법이다. 요청의 타임스탬프를 추적하여 새 요청이 오면 만료된 타임 스탬프(현재 윈도의 시작 시점보다 오래된 타임스탬프)는 제거하고 새 요청의 타임스탬프를 로그에 추가한다. 로그의 크기가 혀용치보다 같거나 작으면 요청을 시스템에 전달하고 그렇지 않는 경우에는 처리를 거부한다.

**장점**

- 매우 정교한 알고리즘이기 때문에 항상 허용되는 요청의 개수는 시스템의 처리율 한도를 넘지 않는다.

**단점**

- 거부된 요청의 타임스탬프도 보관하기 때문에 다량의 메모리를 사용한다.

### 이동 윈도우 카운터 알고리즘

고정 윈도 카운터 알고리즘과 윈도 로깅 알고리즘을 결합한 것이다.

```
현재 윈도의 요청 개수 - 현재 1분간의 요청 수 + 직전 1분간의 요청 수 * 이동 윈도와 직전 1분이 겹치는 비율
```

**장점**

- 메모리 효율이 좋다.
- 이전 시간대의 평균 처리율에 따라 현재 윈도의 상태를 계산하므로 짧은 시간에 몰리는 트래픽에도 잘 대응한다.

**단점**

- 직전 시간대에 도착한 요청이 균등하게 분표되어 있다고 가정한 상태에서 추정치를 계산하기 때문에 다소 느슨하다.

---

### 정리

처리율 제한 알고리즘의 기본 아이디어는 단순하다. 얼마나 많은 요청이 접수되었는지를 추적할 수 있는 카운터를 추적 대상별로 두고 이 카운터의 값이 어떤 한도를 넘어서면 한도를 넘어 도착한 요청은 거부하는 것이다. 카운터는 빠르고 시간에 기반한 만료 정책을 지원하는 캐시에 보관하는 것이 적절하다.

## 상세 설계

### 처리율 규칙 제한

처리율 제한 규칙들은 보통 설정 파일 형태로 디스크에 저장된다. lyft의 오픈소스인 [ratelimit](https://github.com/envoyproxy/ratelimit#overview)을 사용하면 처리율 제한 규칙을 아래와 같이 정의할 수 있다.

```
domain: messaging
descriptors:
  # Only allow 5 marketing messages a day
  - key: message_type
    value: marketing
    descriptors:
      - key: to_number
        rate_limit:
          unit: day
          requests_per_unit: 5
```

### 처리율 제한 장치가 사용하는 HTTP 헤더

어떤 요청이 한도 제한에 걸리면 API는 HTTP 429 응답을 클라이언트에게 보낸다. 클라이언트는 HTTP 응답 헤더를 통해서 자기 요청의 처리율 제한과 관련된 정보들을 얻을 수 있다.

- X-Ratelimit-Remaining : 윈도 내에 남은 처리 가능 요청 횟수
- X-Ratelimit-Limit : 매 윈도마다 클라이언트가 전송할 수 있는 요청의 수
- X-Ratelimit-Retry-After : 한도 제한에 걸리지 않으러면 몇 초 뒤에 요청을 다시 보내야 하는지 알림

### 흐름
클라이언트가 요청을 보내면 먼저 처리율 제한 미들웨어에 요청이 도달한다. 처리율 제한 미들웨어는 제한 규칙을 캐시에서 가져오고 카운터 및 마지막 요청의 타임스탬프를 레디스 캐시에서 가져온다. 가져온 값들에 근거하여 미들웨어는 해당 요청이 처리율 제한에 걸렸는지 아닌지를 판단한다. 한도 제한에 걸렸을 경우, 그냥 요청을 버릴 수도 있지만 요청들을 메세지 큐에 보관하였다가 나중에 처리할 수도 있다.

## 분산 환경에서의 처리율 제한 장치의 구현

여러 대의 서버와 병렬 스레드를 지원하도록 시스템을 확장하는 것은 또 다른 문제다. 경쟁 조건과 동기화 라는 2가지 어려운 문제를 풀어야 하기 때문이다.

### 경쟁 조건 (Race Condition)

만약, 두 개의 요청 스레드가 동시에 레디스에 저장된 counter 값을 읽었을 때, counter 값이 올바르게 변경되지 않는 문제가 발생하게 된다. 이러한 경쟁 조건 문제를 해결하는 가장 널리 알려진 방법은 락이지만, 락은 시스템의 성능을 저하시키는 문제가 있다. 때문에 락 대신 사용할 수 있는 해결책이 2가지 있는데 첫번째는 루아 스크립트(Lua Script)이고 다른 하나는 레디스의 자료구조인 정렬 집합(sorted set)을 사용하는 것이다.

1. **루아(Lua) 스크립트**
    
    Lua는 프로그래밍 언어로 스크립팅(Script)을 주 목적으로 설계되었다. Redis에서 루아 스크립트를 지원하는데 복잡한 연산을 원자적으로 처리할 수 있게 해준다. 즉, Lua 스크립트를 활용하면 모든 명령을 **원자적으로 실행**할 수 있게 되어 데이터의 비일관성 문제가 해결된다.
    
2. **정렬 집합 (Sorted Set)**
정렬 집합은 각 요소가 고유한 값을 가지며, 점수(score)에 따라 자동으로 정렬되는 자료구조이다. 정렬 집합이 지원하는 **원자적**으로 동작하는 여러 명령어를 통해 경쟁 상태를 해결할 수 있다.

### 동기화 (Synchronization)

처리율 제한 장치를 여러 대 두게 되면 동기화가 필요해 진다. 웹 계층은 무상태이므로 클라이언트의 요청은 랜덤으로 2개의 처리량 제한 장치에게 보내지게 된다. 이때, 동기화를 하지 않는다면 클라이언트에 대해 정보가 없어 처리율 제한을 올바르게 수행할 수 없는 문제가 발생한다.

이에 대한 해결책은 **고정 세션**을 활용하여 같은 클라이언트로부터의 요청은 항상 같은 처리율 제한 장치로 보낼 수 있도록 하는 것이다. 하지만 이 방법은 규모 면에서 확장 가능하지도 않고 유연하지도 않은 방법이기 때문에 추천하지 않는다. 더 나은 방법은 레디스와 같은 **중앙 집중형 데이터 저장소를 쓰는 것**이다.

### 성능 최적화

제한 장치 간의 데이터를 동기화할 때 고려해야 할 점은 **최종 일관성 모델을 사용**하는 것이다.

일관성 모델에 대해서는 6장에 기술되어 있으니 참고하자.

### 모니터링

처리율 제한 장치를 설치한 이후에는 효과적으로 동작하고 있는지를 보기 위해 데이터를 모을 필요가 있다. 모니터링을 통해 확인하려는 것은 다음 2가지이다.

- 채택된 처리율 제한 알고리즘이 효과적이다.
- 정의한 처리율 제한 규칙이 효과적이다.

처리율 제한 규칙이 만약 너무 빡빡하다면 많은 유효 요청들이 무시될 것이다. 때문에 적절한 처리율 제한 규칙을 정하는 것이 중요하다, 또한 이벤트로 인해 트래픽이 급증할 때 이런 트래픽 패턴을 잘 처리할 수 있도록 알고리즘을 바꾸는 것도 한번 생각해보자.

## 마무리

면접에서 시간이 허락한다면 다음과 같은 부분도 함께 언급하면 도움이 될 것이다.

### 경성(hard) 또는 연성(soft) 처리율 제한

- 경성 처리율 제한 : 요청의 개수는 임계치를 절대 넘어설 수 없다.
- 연성 처리율 제한: 요청 개수는 잠시 동안은 임계치를 넘어설 수 없다.

### 다양한 계층에서의 처리율 제한

이번 장에서는 애플리케이션 계층의 처리율 제한에 대해서만 살펴보았다. 하지만 다른 계층에서도 처리율 제한이 가능하다. 예를 들어 Iptables를 사용하면 IP 주소에 처리율 제한을 적용하는 것이 가능하다.

### 처리율 제한을 회피하는 방법 → 클라이언트 설계

- 클라이언트 측 캐시를 사용하여 API 호출 횟수를 줄인다.
- 처리율 제한의 임계치를 이해하고 짧은 시간 동안 너무 많은 메세지를 보내지 않도록 한다
- 예외나 에러를 처리하는 코드를 도입하여 클라이언트가 예외적 상황으로부터 우아하게 복구될 수 있도록 한다
- 재시도 로직을 구현할 때는 충분한 백오프 시간을 둔다.
