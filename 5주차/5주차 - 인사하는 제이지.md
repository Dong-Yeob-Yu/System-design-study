# 9장 웹 크롤러 설계
* 웹 크롤러는 로봇 또는 스파이더라고도 부른다.
* 검색 엔진에서 널리 쓰는 기술로, 웹에 새로 올라오거나 갱신된 콘텐츠를 찾아내는 것이 주된 목적이다.
## 웹 크롤러 활용처
### 검색 엔진 인덱싱
* 크롤러의 가장 보편적인 용례
* 크롤러는 웹 페이지를 모아 검색 엔진을 위한 로컬 인덱스를 만든다.
### 웹 아카이빙
* 나중에 사용할 목적으로 장기 보관하기 위해 웹에서 정보를 모으는 절차
* 국립 도서관이 크럴러를 돌려 웹 사이트를 아카이빙 하고 있다.
### 웹 마이닝
* 웹 마이닝을 통해 인터넷에서 유용한 지식을 도출해 낼 수 있다.
* 유명 금융 기업들은 크롤러를 사용해 주주 총회 자료나 연차 보고서를 다운받아 기업의 핵심 사업 방향을 알아내기도 한다.
### 웹 모니터링
* 크롤러를 사용하면 인터넷에서 저작권이나 상표권이 침해되는 사례를 모니터링할 수 있다.
## 설계를 위한 문제 이해 및 설계 범위 확정
### 크롤러의 기본 동작 원리
1. URL 집합이 입력으로 주어지면, 해당 URL들이 가리키는 모든 웹 페이지를 다운로드한다.
2. 다운받은 웹 페이지에서 URL들을 추출한다.
3. 추출된 URL들을 다운로드할 URL 목록에 추가하고 위의 과정을 처음부터 반복한다.
### 설계 고려사항
* 규모 확장성: 거대한 웹의 데이터를 수집하기 위해 병행성(parallelism)을 활용하면 보다 효과적인다.
* 안정성(robustness): 웹은 함정으로 가득하다. 잘못 작성된 HTML, 아무 반응 없는 서버, 장애, 악성 코드가 붙은 링크 등의 환경에 대응할 수 있어야 한다. 
* 예절(politeness): 크롤러는 수집 대상 웹 사이트에 짧은 시간 동안 너무 많은 요청을 보내서는 안 된다. 
* 확장성(extensibility): 새로운 형태의 콘텐츠를 지원하기가 쉬워야 한다. (ex. 이미지 파일)

### 개략적 설계 규모 추정
* 매달 10억 개의 웹 페이지를 다운로드한다.
* QPS = 10억 / 30일 / 24시간 / 3600초 = 대략 400 tps
* 최대 QPS = 2 * QPS = 800
* 웹 페이지 크기 평균: 500k로 가정
* 10억 * 500k = 500TB/월
* 1개월치 데이터를 보관하는데는 500TB 5년간 보관한다고 가정하면 500TB * 12개월 * 5년 = 30PB 용량 필요

## 개략적 설계안 제시 및 동의 구하기
![웹 크롤러 플로우](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-vGB39igy4qJ1oKkyby2-A.png)
### 시작 URL 집합
* 웹 크롤러가 크롤링을 시작하는 출발점
* 크롤러가 가능한 많은 링크를 탐색할 수 있도록 URL을 고르는 것이 바람직함
* 일반적으로 URL 공간을 작은 부분집합으로 나누는 전략을 쓴다.
### 미수집 URL 저장소
* 보통 크롤링 상태를 (1) 다운로드할 URL (2) 다운로드된 URL 두 가지로 나눠 관리함
* 이 중 다운로드할 URL을 저장 관리하는 컴포넌트를 미수집 URL 저장소라고 부른다.
* 보통 FIFO 큐 형태로 구현됨
### HTML 다운로더
* 웹 페이지를 다운로드하는 컴포넌트
### 도메인 이름 변환기
* 웹 페이지를 다운받으려면 URL을 IP 주소로 변환하는 절차가 필요

### 콘텐츠 파서
* 웹 페이지를 다운로드하면 파싱과 검증 절차를 거쳐야 한다.
* 이상한 웹 페이지는 문제를 일으킬 수 있는데다 저장 공간만 낭비하기 때문이다.
* 크롤링 서버 안에 콘텐츠 파서를 구현하면 크롤링 과정ㅇ ㅣ느려지게 될 수 있으므로, 독립된 컴포넌트로 만들었다.

### 중복된 콘첸츠인가?
* 연구 결과에 따르면, 29% 가량의 웹 페이지 콘텐츠는 중복이다.
* 중복을 해결하고 데이터 처리에 소요되는 시간이 줄어들 수 있는 방법을 찾아야 한다.
* 가장 간단하고 효과적인 중복 검증 방법은 HTML 문서의 해시 값을 비교하는 것

### 콘텐츠 저장소
* HTML 문서를 보관하는 시스템
* 저장할 데이터의 유형, 크기, 저장소 접근 빈도, 데이터의 유효 기간 등을 종합적으로 고려해야 함
* 데이터 양이 너무 많으므로 대부분의 콘텐츠는 디스크에 저장한다.
* 인기 있는 콘텐츠는 메모리에 두어 접근 지연시간을 줄일 것이다.

### URL 추출기
* HTML 페이지를 파싱하여 링크들을 골라는 역할

### URL 필터
* URL 필터는 특정 콘텐츠 타입이나 파일 확장자를 갖는 URL 접속 시 오류가 발생하는 URL, 접근 제외 목록에 포함된 URL 등을 크롤링 대상에서 배제하는 역할을 한다.

### 이미 방문한 URL
* 이미 방문한 URL이나 미수집 URL 저장소에 보관된 URL을 추적할 수 있는 자료 구조 사용
* 이미 방문한 적 있는 URL인지 추적하면 같은 URL을 여러 번 처리하는 일을 방지할 수 있음
* 또한 서버 부하를 줄이고 시스템이 무한 루프에 빠지는 일을 방지할 수 있음
* 해당 자료 구조로는 블룸 필터나 해시 테이블이 널리 쓰임

### URL 저장소
* URL 저장소는 이미 방문한 URL을 보관하는 저장소

### 웹 크롤러 작업 흐름
1. 시작 URL들을 미수집 URL 저장소에 저장
2. HTML 다운로더는 미수집 URL 저장소에서 URL 목록을 가져옴
3. HTML 다운로더는 도메인 이름 변환기를 사용하여 URL의 IP 주소를 알아내고, 해당 IP 주소로 접속하여 웹 페이지를 다운받는다.
4. 콘텐츠 파서는 다운된 HTML 페이지를 파싱하여 올바른 형식을 갖춘 페이지인지 검증한다.
5. 콘텐츠 팡싱과 검증이 끝나면 중복 콘텐츠인지 확인하는 절차를 개시한다.
6. 중복 콘텐츠인지 확인하기 위해서, 해당 페이지가 이미 저장소에 있는지 본다.
   * 이미 저장소에 있는 콘텐츠인 경우에는 처리하지 않고 버린다.
   * 저장소에 없는 콘텐츠인 경우에는 저장소에 저장한 뒤 URL 추출기로 전달한다.
7. URL 추출기는 해당 HTML 페이지에서 링크를 골라낸다.
8. 골라낸 링크를 URL 필터로 전달한다.
9. 필터링이 끝나고 남은 URL만 중복 URL 판별 단계로 전달한다.
10. 이미 처리한 URL인지 확인하기 위하여, URL 저장소에 보관된 URL인지 살핀다. 이미 저장소에 있는 URL은 버린다.
11. 저장소에 없는 URL은 URL 저장소에 저장할 뿐 아니라 미수집 URL 저장소에도 전달한다.

## 상세 설계
### DFS vs BFS
* 웹은 유향 그래프와 같다.
* 페이지는 노드이고, 하이퍼링크는 에지라고 보면 된다.
* DFS는 웹의 그래프 깊이를 가늠할 수 없으므로 보통 BFS를 사용한다.
* BFS 구현시 문제점이 있다.
  * 한 페이지에서 나오는 링크의 상당수는 같은 서버로 되돌아간다는 점 (중복 크롤링)
  * URL간에 우선순위를 두지 않는 점
### 미수집 URL 저장소
* 이 저장소를 잘 구현하면
  * 예의를 잘 갖춘 크롤러를 구현할 수 있다.
  * URL 사이의 우선순위와 신선도를 구별하는 크롤러를 구현할 수 있다.
#### 예의
* Dos 공격이 되지 않도록 동일 웹 사이트에 대해서는 한 번에 한 페이지만 요청해야 한다.
  * 같은 웹 페이지를 다운받는 태스크는 시간차를 두고 실행하도록 설계되어야 함
* 같은 호스트에 속한 URL은 언제나 같은 큐로 가도록 매핑한다.
* 작업 스레드가 일정 지연 시간을 두고 큐에 있는 작업을 수행할 수 있게 분배한다.
#### 우선순위
* 중요도 있는 페이지의 수집이 우선되도록 설계해야 함
* 유용성에 따라 URL의 우선순위를 나눌 때 페이지 랭크, 트래픽 양, 갱신 빈도 등 다양한 척도를 사용할 수 있을 것이다.
* 순위결정장치는 URL 우선순위를 정하는 컴포넌트다.

#### 종합
* 두 가지 방식을 결합한 전체 설계
  * 전면 큐: 우선순위 결정 과정을 처리
  * 크롤러가 예의 바르게 동작하도록 보장
![미수집 URL 저장소 플로우](https://miro.medium.com/v2/resize:fit:1120/format:webp/1*WGb5D48c67k0wCXHeiIpMw.png)

#### 신선도
* 웹 페이지는 수시로 추가되고, 삭제되고, 변경된다.
* 신선도를 유지하기 위해서는 재수집이 필요하다.
* 이를 최적화하기 위한 전략들이 있음
  * 웹 페이지의 변경 이력 활용 (이건 결국 페이지의 변경 이력을 한 번씩 확인해줘야 하는거 아닌지?)
  * 우선순위를 활용하여, 중요한 페이지는 좀 더 자주 재수집
#### 미수집 URL 저장소를 위한 지속성 저장장치
* 대부분의 URL은 디스크에 두지만 IO 비용을 줄이기 위해 메모리 ㅍ버퍼에 큐를 두기

### HTML 다운로더
#### 로봇 제외 프로토콜(Robots.txt)
* robots.txt는 웹사이트가 크롤러와 소통하는 표준적 방법이다.
    * 이 파일에는 크롤러가 수집해도 되는 페이지 목록이 들어 있다.
* 따라서 웹 사이트를 긁어 가기 전에 크롤러는 해당 파일에 나열된 규칙을 먼저 확인해야 함
#### 성능 최적화
1. 분산 크롤링: 성능을 높이기 위해 크롤링 작업을 여러 서버에 분산하는 방법
    * 각 서버는 여러 스레드를 도ㅓㄹ려 다운로드 작업을 처리한다.
2. 도메인 이름 변환 결과 캐시
    * DNS Resolver는 크롤러 성능의 병목 중 하나인데, 이는 DNS 요청을 보내고 결과를 받는 작업의 동기적 특성 때문이다.
    * DNS 요청이 처리되는 데는 보통 10ms에서 200ms가 소요된다.
    * 따라서 DNS 조회 결과로 얻어진 도메인 이름과 IP 주소 사이의 관계를 캐시에 보관해놓고 cron job 등을 돌려 주기적으로 갱신하도록 해 놓는 것이 좋다.
3. 지역성
    * 크롤링 작업을 수행하는 서버를 대상 서버를 고려하여 지역별로 분산하는 방법
4. 짧은 타임아웃
    * 응답이 느리거나, 없는 웹 서버를 대비해서 타임 아웃을 설정해야 함
### 안정성 확보 전략
* 안정 해시: 다운로더 서버들에 부하를 분산할 때 적용 가능한 기술이다.
* 크롤링 상태 및 수집 데이터 저장: 장애가 발생한 경우에도 쉽게 복구할 수 있도록 백업해두는 것
* 예외 처리: 적절한 에러 핸들리을 통해 작업을 우아하게 이어나갈 수 있어야 함
* 데이터 검증: 시스템 오류를방지하기 위한 중요 수단
### 확장성 확보 전략
* 새로운 형태의 콘텐츠를 쉽게 지원할 수 있도록 신경 써야 한다.
* 확장이 가능한 구조로 설계해서 모듈을 추가하여 적절한 확장이 가능하도록 만들어야 함
### 문제 있는 콘텐츠 감지 및 회피 전략
#### 중복 콘텐츠
* 해시나 체크섬을 사용하면 중복 콘텐츠를 보다 쉽게 탐지할 수 있다.
#### 거미 덫
* 크롤러를 무한 루프에 빠뜨리도록 설계한 웹 페이지
* 간단한 덫은 URL 최대 길이를 제한하는 식으로 회피할 수 있다.
* 변칙적인 덫은 사람이 수작업으로 확인하여 크롤러 탐색 대상에서 제외하거나 URL 필터 목록에 걸어두는 것

#### 데이터 노이즈
* 가치가 없는 페이지는 탐색 대상에서 제외해야 함

## 마무리
### 서버 측 렌더링
* 동적인 페이지 데이터를 크롤링하기 위해 페이지를 파싱하기 전에 페이지를 렌더링하여 크롤링한다.
### 원치 않는 페이지 필터링
* 스팸 방지 컴포넌트를 두어 품질이 조악하거나 스팸성인 페이지를 걸러내도록 한다.
### 데이터베이스 다중화 및 샤딩
* 안정적인 데이터 소스를 만드는게 좋음
### 수평적 규모 확장성
* 대규모 크롤링을 위해서 확장이 필요할 수 있음
### 가용성, 일관성, 안정성
* 항상 중요
### 데이터 분석 솔루션
* 데이터를 수집하고 분석하는 시스템을 붙이는게 좋다.
# 10장 알림 시스템 설계
* SMS, PUSH 등 사용자에게 알림을 보내주는 시스템
## 설계를 위한 문제 이해 및 설계 범위 확정
* soft real-time
* IOS, android, laptop, desktop 지원해야 함
* 클라이언트 측에서 직접 생성하거나, 서버에서 스케줄링할 수 있음
* 사용자가 알림을 차단할 수 있어야 함
* 하루에 1000만건의 push 알람, 100만건의 sms 메시지, 500만건의 email을 보낼 수 있어야 함
## 개략적 설계안 제시
### 알림 유형별 지원 방안
#### IOS 푸시 알림
* 알림 제공자: 알림 생성 주체
  * 단말 토큰: IOS 수신자 고유 식별자
  * 페이로드: 알람 내용
* APNS: 애플이 제공하는 원격 서비스
  * 푸시 알림을 IOS로 보내는 역할
* IOS 단말: 푸시 알림을 수신하는 사용자 단말
#### 안드로이드 푸시 알림
* IOS와 비슷하고, APNS 대신 FCM을 사용한다.
#### SMS 메시지
* 비슷한 형태이며 서비스 대부분이 상용 서비스라 이용요금 발생
#### 이메일
* 대부분의 회사는 고유 이메일 서버를 구축할 역량을 갖추고 있다.
### 역락처 정보 수집 절차
* 단말기로 보낼 연락처 정보를 저장할 저장소가 필요
* 일부 서비스는 발신자 정보도 필요할 텐데 그 부분이 안 보임

### 알림 전송 및 수신 절차
#### 개략적 설계
* 알림 시스템은 여러 서비스로부터 알림 발송 요청을 받아서 발송을 담당하는 서버로 대신 보내주는 역할을 한다.
* 이 과정에서 알림 제공자를 위한 API를 제공해야 하고
* 각 제3자 서비스에 전달할 알림 페이로드를 만들 수 있어야 함
* 제3자 서비스와 쉽게 통합할 수 있는 확장성을 고려해야 함
* SPOF, 규모 확장성, 성능 병목을 신경써야 함
#### 개선된 설계
* DB와 캐시를 알림 시스템의 주 서버에서 분리
* 알림 서버를 증설하고 자동으로 auto-scaling될 수 있게 설계
* 메시지 큐를 이용해서 컴포넌트 사이의 결합을 끊음
![알림 시스템](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XO6xxoSLaWwyudZhR5-Yxg.png)

## 상세 설계
### 안정성
* 데이터 손실 방지: 어떤 상황에서도 데이터가 소실되면 안 되기 때문에 알림 로그 데이터베이스 등으로 유실시 복구가 가능하게 설계해야 함
* 알림 중복 전송 방지: 이벤트 ID를 검사하여 중복 이벤트를 drop함
  * 중복 전송이 100% 방지되는 것은 불가능하다.
### 추가로 필요한 컴포넌트 및 고려사항
* 알림 템플릿: 비슷한 메시지를 재활용해서 사용할 데이터
* 알림 설정: 사용자가 알림 설정을 상세히 조정할 수 있도록 하는 기능 (여기서 의미하는 사용자는 클라이언트인가 수신자인가...)
* 전송률 제한: 너무 많은 알림을 한 번에 보내지 않도록 하는 것. 한 사용자가 받을 수 있는 알림의 빈도를 제한하는 것
* 재시도 방법: 재시도 전용 큐 등으로 알림이 발송되도록 설계
* 푸시 알림과 보안: 특정 단말들은 보안 요구 사항들이 있음
* 큐 모니터링: 메트릭을 수집하여 시스템 운영과 개선에 활용 (scale-out 여부나 장애 감지)
* 이벤트 추적: 수신자의 이용률을 분석하는 시스템 제공
### 개선된 설계안
* 알림서버에 인증과 전송률 제한 추가
* 전송 실패에 대응하는 재시도 기능 추가
* 전송 템플릿같은 편의 기능 제공
* 모니터링과 추적 시스템을 추가하여 모니터링


# 그림 출처
* https://medium.com/@ishwarya1011.hidkimath/system-design-web-crawler-a7dfbfd51474
* https://medium.com/@meenak1996/system-design-of-notification-system-8c2828be3e8e