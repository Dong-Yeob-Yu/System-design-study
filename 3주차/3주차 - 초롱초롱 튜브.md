# 5장. 안정 해시 설계

수평적 규모 확장성 달성을 위해서는 요청 또는 데이터를 서버에 균등하게 분배하는 것이 중요한데, 이를 위해 보편적으로 안정 해시라는 기술을 사용한다.

## 해시 키 재배치(rehash) 문제

N개의 캐시 서버들에 부하를 균등하게 분배하는 보편적인 방법은 아래의 해시 함수를 사용하는 것이다.

`serverIndex = hash(key) % N`

이 방법은 대부분의 경우 잘 작동하지만 **서버 풀(server pool)의 크기가 변경되거나, 데이터 분포가 균등하지 않는 경우**에는 문제가 발생한다. 특히 서버가 추가/제거된다면 서버 인덱스 값들이 달라져 대량의 캐시 미스가 발생하는데, 이를 안정 해시로 해결할 수 있다.

## 안정 해시

**안정 해시**(consistent hash)는 해시 테이블 크기가 고정될 때 **평균적으로 오직 k/n개의 키만 재배치**하는 해시 기술이다. (k = 키의 개수, n = 슬롯의 개수) 대부분의 전통적 해시 테이블에서는 이와 달리 슬롯의 수가 바뀌면 거의 대부분의 키를 재배치한다.

### 안정 해시의 이점

서버가 추가/삭제될 때 재배치되는 키의 수를 최소화한다.

데이터를 보다 균등하게 분포시킬 수 있다. → 수평적 규모 확장성을 달성하기 쉽다.

특정 샤드에 대한 접근이 지나치게 자주 발생하는 핫스팟(hotspot) 키 문제를 줄인다.

### 안정 해시의 기본 구현법

해시 함수 f로 SHA-1을 사용하고, 이 함수의 출력값 범위는 x0, x1, .., xn이라고 하자.

SHA-1의 **해시 공간**(hash space) 범위는 0부터 $2^{160}$ - 1이므로 x0은 0, xn은 $2^{160}$ - 1이며, 나머지는 그 사이의 값을 갖게 된다.

![image](https://github.com/user-attachments/assets/7474e309-e05d-4744-9626-41045d856d52)

해시 공간의 양쪽을 구부려 접으면 **해시 링**(hash ring)이 만들어진다.

<img src="https://github.com/user-attachments/assets/f405a875-8ef0-48ce-9c2e-81eaa46ff159" width="440" height="450"/>

안정 해시 알고리즘은 MIT에서 처음 제안되었는데, 기본 절차는 다음과 같다.

- 서버와 키를 **균등 분포**(uniform distribution) 해시 함수를 사용해 해시 링에 배치한다. 여기에서 사용되는 해시 함수는 “해시 키 재배치 문제”의 함수와 다르며, 나머지 연산 %을 사용하지 않는다.
  
- 키는 해당 키의 위치로부터 시계 방향으로 링을 탐색할 때 첫 번째로 만나는 서버에 저장된다.

![image](https://github.com/user-attachments/assets/b796299e-9abd-4f70-b393-3c078de0e884)

서버가 추가 또는 제거되더라도 **키의 일부만 재배치**하면 되므로 나머지 키에는 영향을 주지 않는다. 이때 *재배치된 노드와 그로부터 반시계 방향에 있는 첫 번째 서버 사이*의 키만이 재배치된다.

### 기본 구현법의 두 가지 문제

안정 해시 알고리즘의 기본 구현법에는 두 가지 문제가 있다.

첫 번째 문제는 서버가 추가/제거되는 상황을 감안하면 **파티션(partition)의 크기를 균등하게 유지하는 게 불가능**하다는 것이다. 파티션이란 인접한 서버 사이의 해시 공간으로, 즉 각 서버들이 할당받는 해시 공간의 크기가 각각 달라지는 것이다.

두 번째 문제는 **키의 균등 분포를 달성하기가 어렵다**는 것이다.

이 문제들을 해결하기 위해 도입된 기법이 **가상 노드**이다.

### 가상 노드 (virtual node)

가상 노드는 실제 노드 또는 서버를 가리키는 노드로서, 하나의 서버는 링 위에 여러 개의 가상 노드를 가질 수 있다. 각 서버는 가상 노드에 의해 생기는 여러 개의 파티션을 관리해야 한다.

![image](https://github.com/user-attachments/assets/870f2187-282c-4fca-9240-e1c9a3f7f396)

키가 저장되는 서버를 결정하는 방법은 동일한데, 키가 처음으로 만나는 노드가 가상 노드라면 그 노드가 가리키는 실제 서버에 키가 저장된다.

**가상 노드가 많아질수록 키의 분포가 더 균등**해지지만, 가상 노드 데이터를 저장하기 위해 더 많은 공간이 요구된다. 시스템 요구사항에 맞게 tradeoff가 발생하는 것이다.

# 6장. 키-값 저장소 설계

**키-값 저장소**(key-value store)는 키-값 데이터베이스라고도 불리는 비 관계형 데이터베이스로, 저장되는 모든 값은 각각 고유 식별자(identifier)인 키와 **키-값 쌍**을 이룬다. 키는 서로 중복되어서는 안되며, 값은 매핑된 키를 통해서만 접근할 수 있다.

## 단일 서버 키-값 저장소

단일 서버만 사용하는 가장 직관적인 방법은 **키-값 쌍 모두를 메모리에 해시 테이블로 저장**하는 것이다. 이 방법은 빠른 속도를 보장하지만 모든 데이터를 메모리 안에 두는 것이 불가능할 수도 있다.

`데이터 압축` 또는 `자주 쓰이는 데이터만 메모리에 캐싱하고 나머지는 디스크에 저장`하는 방식으로 개선할 수 있으나, 많은 양의 데이터를 저장하기 위해서는 한 대의 서버로는 부족하다.

## 분산 키-값 저장소

### CAP 정리

> **CAP 정리**는 데이터 일관성(consistency), 가용성(availability), 파티션 감내(partition tolerance)라는 요구사항을 **동시에 만족하는 분산 시스템을 설계하는 것은 불가능하다**는 정리다.

- **데이터 일관성** : 분산 시스템에 접속하는 모든 클라이언트는 **어떤 노드에 접속했는지와 무관하게** **언제나 같은** 데이터를 볼 수 있어야 한다.
  
- **가용성** : 분산 시스템에 접속하는 모든 클라이언트는 **일부 노드에 장애가 발생하더라도 항상 응답을 받을** 수 있어야 한다.
  
- **파티션 감내** : 파티션은 두 노드 사이에 통신 장애가 발생하였음을 의미한다. 파티션 감내는 **네트워크에 파티션이 생기더라도 시스템은 계속 동작해야 한다**는 것을 뜻한다.

이 세 가지 요구사항 중 어느 두 가지를 만족하느냐에 따라 키-값 저장소를 다음과 같이 분류할 수 있다.

- CP 시스템 : 일관성/파티션 감내 지원, 가용성 희생
  
- AP 시스템 : 가용성/파티션 감내 지원, 데이터 일관성 희생
  
- CA 시스템 : 일관성/가용성 지원, 파티션 감내 미지원 → but 통상 네트워크 장애는 불가피하므로 분산 시스템은 반드시 파티션 문제를 감내할 수 있어야 함. 따라서 실세계에 CA 시스템은 존재하지 않음.

분산 시스템에서 파티션 문제가 발생하면 **일관성과 가용성 중 하나**를 선택해야 한다.

가용성 대신 일관성을 선택한다면, 클라이언트에게 잠시 오류를 반환하더라도 살아있는 서버에 대해 쓰기 연산을 중단시킨다. 은행권 시스템에서 주로 이 방식을 선택한다.

반대로 일관성 대신 가용성을 선택한다면, 낡은 데이터를 반환하더라도 계속 읽기 연산을 허용하여 클라이언트는 항상 응답을 받을 수 있다.

### 시스템 컴포넌트

키-값 저장소 구현에 사용될 핵심 컴포넌트 및 기술들을 살펴보자.

<hr/>

#### 데이터 파티션

대규모 애플리케이션에서는 **전체 데이터를 작은 파티션들로 분할하여 여러 대의 서버에 저장**한다.

데이터를 파티션 단위로 나눌 때 `데이터를 여러 서버에 고르게 분산할 수 있는지`, `노드가 추가/제거될 때 데이터의 이동을 최소화할 수 있는지`가 중요한데, 이는 5장에서 다뤘던 **안정 해시**를 통해 달성할 수 있다. 다음과 같은 이점을 얻을 수 있다.

- **규모 확장 자동화(automatic scaling)** : 시스템 부하에 따라 서버가 자동으로 추가/제거되도록 만들 수 있다.
  
- **다양성(heterogeneity)** : 각 서버의 용량에 맞게 가상 노드의 수를 조정할 수 있다.

<hr/>

#### 데이터 다중화

높은 가용성과 안정성을 위해 **데이터를 N개의 서버에 비동기적으로 다중화**하는 것이 좋다. 이때 ‘N개 서버’는 해시 링 위의 각 키에서 시계 방향으로 탐색할 때 만나는 첫 N개의 서버이다.

하지만 가상 노드를 사용한다면 N개의 노드에 대응되는 **실제 물리 서버의 개수는 N보다 작아질** 수 있다. 이는 노드 선택 시 **같은 물리 서버를 중복 선택하지 않음**으로써 해결할 수 있다.

<hr/>

#### 데이터 일관성

여러 노드에 다중화된 데이터는 적절히 동기화되어야 하는데, 이때 **정족수 합의 프로토콜**을 사용하여 읽기/쓰기 연산에 일관성을 보장할 수 있다.

> N = 사본 개수
>
> W = 쓰기 연산에 대한 정족수
> 
> R = 읽기 연산에 대한 정족수

클라이언트와 노드 사이에서 proxy 역할을 하는 중재자는 R 또는 W대의 노드로부터 성공 응답을 받았다면 더이상 응답을 기다리지 않는다.

응답 지연과 데이터 일관성 간의 trade-off를 통해 W, R, N을 정하는데, `W + R > N`인 경우에는 **강한 일관성**이 보장된다.

> R = 1, W = N : 빠른 읽기 연산에 최적화된 시스템
>
> W = 1, R = N : 빠른 쓰기 연산에 최적화된 시스템
>
> W + R > N : 강한 일관성이 보장됨
>
> W + R ≤ N : 강한 일관성이 보장되지 않음

<hr/>

#### 일관성 모델

데이터 일관성의 수준을 결정하는 일관성 모델에는 다양한 종류가 있다.

- 강한 일관성(strong consistency) : 모든 읽기 연산은 가장 최근에 갱신된 결과를 반환한다.
  
- 약한 일관성(weak consistency) : 읽기 연산은 가장 최근에 갱신된 결과를 반환하지 못할 수 있다.
  
- 최종 일관성(eventual consistency) : 약한 일관성의 한 형태로, 갱신 결과가 결국에는 모든 사본에 반영(동기화)되는 모델이다.

강한 일관성은 모든 사본에 현재 쓰기 연산의 결과가 반영될 때까지 해당 데이터에 대한 읽기/쓰기를 금지함으로써 달성할 수 있다. 그러나 새로운 요청은 무조건 대기해야 하므로 고가용성 시스템에는 적합하지 않다.

다이나모, 카산드라 등의 저장소가 채택한 **최종 일관성 모델**에 따라 설계하는 것이 좋다. 쓰기 연산이 병렬적으로 발생하면 저장된 데이터의 일관성이 깨질 수 있는데, 이는 버저닝(versioning)과 벡터 시계(vector clock)를 통해 클라이언트 측에서 해결할 수 있다.

<hr/>

**일관성 불일치 해소(inconsistency resolution)**

**버저닝**은 데이터를 **변경할 때마다 해당 데이터의 새로운 버전을 만드**는 것으로, 각 버전의 데이터는 변경 불가능(immutable)하다.

하나의 데이터에 대해 여러 데이터 센터에서 변경함에 따라 여러 버저닝이 생기는데, 이로 인해 충돌이 발생할 수 있다. 이때 충돌을 발견 및 자동으로 해결할 버저닝 시스템이 바로 **벡터 시계**이다.

벡터 시계는 [서버, 버전]의 순서쌍을 데이터에 추가한 것이다. 이를 통해 선행/후행 버전 여부, 다른 버전과의 충돌 여부를 알 수 있다.

`X의 모든 버전 값 ≤ Y의 모든 버전 값`이라면 버전 X가 버전 Y의 이전 버전이다. 예를 들면 D([s0, 1], [s1, 1])은 D([s0, 1], [s1, 2])의 이전 버전이므로 두 데이터는 충돌하지 않는다.

그러나 `동일 서버의 데이터에 대해 Y의 구성요소 값 중 X의 구성요소 값보다 작은 것이 하나라도 존재`한다면 버전 X와 버전 Y가 충돌했다는 것이다. D([s0, 1], [s1, 2])와 D([s0, 2], [s1, 1])가 충돌하는 것처럼 말이다.

벡터 시계를 이용해 충돌을 처리하는 데에는 두 가지 단점이 있다. 첫 번째는 충돌 감지 및 해소 로직이 클라이언트에 들어가야 하므로, **클라이언트 구현이 복잡해진다**는 것이다.

두 번째는 [서버, 버전]의 순서쌍 개수가 **굉장히 빨리 늘어난다**는 것이다. 이는 순서쌍 개수에 임계치를 설정하여, 이를 초과하면 벡터 시계에서 제거함으로써 해결할 수 있다.

<hr/>

**장애 감지 및 장애 처리**

분산 시스템에서는 한 서버의 장애를 감지할 때 **보통 두 대 이상의 서버의 보고**를 받는다. 이를 위해 모든 노드 사이에 멀티캐스팅(multicasting) 채널을 구축할 수 있다.

하지만 이 방법은 서버가 많을 때에는 비효율적으로, 가십 프로토콜(gossip protocl) 같은 **분산형 장애 감지(decentralized failure detection) 솔루션을 채택**하는 것이 좋다. 동작 원리는 다음과 같다.

1. 각 노드는 멤버십 목록(membership list)을 유지한다. 멤버십 목록은 각 멤버 ID와 박동 카운터(heartbeat counter) 쌍의 목록이다.
   
2. 각 노드는 주기적으로 자신의 박동 카운터를 증가시킨다.
   
3. 각 노드는 무작위로 선정된 노드들에게 주기적으로 자기의 박동 카운터 목록을 보낸다.
   
4. 박동 카운터 목록을 받은 노드는 멤버십 목록을 최신 값으로 갱신한다.
   
5. 어떤 멤버의 박동 카운터 값이 지정된 시간 동안 갱신되지 않으면 해당 멤버는 장애(offline) 상태인 것으로 간주한다.
   
<br/>

이렇게 가십 프로토콜로 장애를 감지한 시스템은 **일시적 장애 처리**를 위해 엄격한 정족수 접근법이나 느슨한 정족수 접근법을 사용할 수 있다.

엄격한 정족수 접근법을 쓴다면, 앞서 본 대로 읽기와 쓰기 연산을 금지해야 한다.

**느슨한 정족수 접근법**을 쓴다면, 조건을 완화하여 가용성을 높일 수 있다. 장애 상태인 서버로 가는 요청들을 장애 상태가 아닌 서버들 중 선택된 서버들이 처리한다.

장애 상태인 서버가 복구되면 그동안 발생한 변경사항을 일괄 반영하여 데이터 일관성을 보존하는 것이다. 이를 위해 임시로 쓰기 연산을 처리한 서버에 그에 대한 단서(hint)를 남겨둔다.

이를 **단서 후 임시 위탁(hinted handoff)** 기법이라고 한다.

<br/>

그렇다면 **영구적 장애 처리**는 어떻게 해야 할까? **반-엔트로피(anti-entropy) 프로토콜**을 구현하여 **사본들을 동기화**할 수 있다.

반-엔트로피 프로토콜은 사본들을 비교하여 최신 버전으로 갱신하는 과정을 포함한다. 사본 간의 일관성이 깨진 상태를 감지하고 전송 데이터의 양을 줄이기 위해 해시 트리(hash tree)라고도 불리는 **머클(Merkle) 트리**를 사용한다.

머클 트리를 사용하면 동기화해야 하는 데이터의 양은 **실제로 존재하는 차이의 크기에 비례**할 뿐, 두 서버에 보관된 데이터의 총량과는 무관하다.

<hr/>

#### 쓰기 경로(write path)

노드에 쓰기 요청이 전달되었을 때의 동작 과정을 카산드라의 사례를 통해 살펴보자.

1. 쓰기 요청이 커밋 로그(commit log) 파일에 기록된다.
   
2. 데이터가 메모리 캐시에 기록된다.
 
3. 메모리 캐시가 가득 차거나 임계치에 도달하면, 데이터는 디스크에 있는 SSTable에 기록된다. SSTable(Sorted-String Table)은 <키, 값>의 순서쌍을 정렬된 리스트 형태로 관리하는 테이블이다.

<hr/>

#### 읽기 경로(read path)

노드에 읽기 요청이 전달되었을 때의 동작 과정은 다음과 같다.

1. 데이터가 메모리 캐시에 있는지를 확인한다. 만약 메모리에 있다면 바로 클라이언트에게 반환한다.
   
2. 메모리에 없다면 디스크에서 데이터를 가져와야 한다. 이때 찾는 키가 위치하는 SSTable을 효율적으로 알아내기 위해 보통 블룸 필터(Bloom filter)가 사용되므로, 먼저 블룸 필터를 검사한다.
   
3. 블룸 필터를 통해 어떤 SSTable에 키가 위치하는지 알아낸다.
   
4. SSTable에서 데이터를 가져온다.
 
5. 해당 데이터를 클라이언트에게 반환한다.

<hr/>

#### 정리

분산 키-값 저장소가 가져야 하는 기능 및 그 기능 구현에 이용되는 기술을 최종적으로 정리하면 다음과 같다.

| 목표/문제 | 기술 |
| --- | --- |
| 대규모 데이터 저장 | 안정 해시를 사용해 서버들에 부하 분산 |
| 데이터 파티션, 점진적 규모 확장성, 다양성(heterogeneity) | 안정 해시 |
| 조절 가능한 데이터 일관성 | 정족수 합의 |
| 읽기 연산에 대한 높은 가용성 보장 | 데이터를 여러 데이터 센터에 다중화 |
| 쓰기 연산에 대한 높은 가용성 보장 | 버저닝 및 벡터 시계를 사용한 충돌 해소 |
| 일시적 장애 처리 | 느슨한 정족수 프로토콜, 단서 후 임시 위탁(hinted handoff) |
| 영구적 장애 처리 | 머클 트리(Merkle tree) |
| 데이터 센터 장애 처리 | 여러 데이터 센터에 걸친 데이터 다중화 |
