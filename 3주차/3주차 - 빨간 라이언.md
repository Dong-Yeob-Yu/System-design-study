# 5장

# 해시 키 재배치 문제

해시값을 `% 서버 수` 연산을 통해 특정 서버 인덱스로 매핑할 때, 하나의 서버가 다운되면 해당 인덱스에 대한 재배치가 필요하다.

## 재배치를 하지 않을 경우 발생하는 문제점

1. **다운된 서버로 요청이 전달됨**  
   - 클라이언트가 여전히 해당 서버로 요청을 보내려 하므로 정상적인 응답을 받을 수 없음.
2. **데이터 소실 문제**  
   - 다운된 서버에 저장된 데이터에 접근할 수 없으므로 데이터 유실이 발생할 가능성이 높음.

---

# 안정 해시

해시 키 재배치 문제는 특정 서버가 다운될 경우 큰 리스크를 초래한다.  
안정 해시는 전통적인 해시 테이블과 달리 **해시 공간, 해시 링, 해시 서버, 해시 키** 개념을 이용하여 문제를 해결한다.

- **해시 공간(Hash Space)**: 출력 값의 범위를 0~N-1로 지정하여 사용.
- **해시 링(Hash Ring)**: 해시 공간을 활용해 원형 구조를 형성.
- **해시 서버(Hash Server)**: 해시 함수 `f`를 이용하여 서버의 위치를 해시 링 위에 지정.
- **해시 키(Hash Key)**: 캐시할 키를 해시 링 위에 지정하여 특정 서버에 할당.

서버를 조회할 때, **시계 방향으로 해시 링을 탐색**하여 첫 번째로 만나는 서버에 키를 저장한다.

---

## 안정 해시의 문제점

안정 해시에도 몇 가지 한계가 존재한다.

1. **서버 추가/삭제 시 파티션 크기 불균형**  
   - 서버 개수가 변할 경우 각 서버가 담당하는 키의 개수가 불균등하게 분배될 수 있음.
2. **키의 균등 분포 어려움**  
   - 특정 서버에 트래픽이 집중될 가능성이 있음.

이 문제를 해결하기 위해 **가상 노드(Virtual Node)** 기법을 활용한다.

---

## 가상 노드 (Virtual Node)

**가상 노드**란 실제 노드(서버)를 가리키는 논리적인 노드로, **하나의 서버가 해시 링 위에 여러 개의 가상 노드를 가질 수 있도록** 하는 기법이다.

### 가상 노드의 장점
- 가상 노드의 개수를 증가시키면 **키의 분포가 점점 더 균등해짐**.
- 표준 편차가 감소하여 데이터가 고르게 분포됨.

### 가상 노드의 단점
- 가상 노드의 개수를 늘리면 표준 편차 값은 감소하지만, **더 많은 저장 공간이 필요**하며 성능과 자원 관리 측면에서 **트레이드오프(Trade-off)** 가 필요하다.

---------------------------

# 6장

# 키-값 저장소

비관계형(NoSQL) 데이터베이스로, **고유 식별자 키-값**으로 이루어진 구조를 가진다.  
키-값 쌍에서 **키는 유일해야 하며, 값은 키를 통해서만 접근**할 수 있다.

---

## 단일 서버 키-값 저장소

한 대의 서버만 사용하는 **키-값 저장소**는 설계가 간단하다.  
기본적으로 **해시 테이블(Hash Table)** 을 사용하여 모든 키-값 쌍을 저장하면 된다.

### 단일 서버 방식의 문제점
- 빠른 속도를 보장하지만, 데이터가 많아지면 **메모리에 모든 데이터를 저장할 수 없음**.
- 이를 해결하는 두 가지 방법:
  1. **데이터 압축**
  2. **자주 사용하는 데이터만 메모리에 유지하고 나머지는 디스크에 저장**

---

## 분산 키-값 저장소

**키-값 쌍을 여러 서버에 분산**시키는 방식이며, 분산 시스템을 설계할 때 **CAP 정리**를 이해해야 한다.

### CAP 정리란?
분산 시스템에서 **세 가지 요구사항을 동시에 만족하는 것은 불가능**하다는 이론.

1. **데이터 일관성(Consistency, C)**
   - 분산 시스템에 접속하는 모든 클라이언트는 어떤 노드에 접속했느냐와 상관없이 항상 동일한 데이터를 조회할 수 있어야 한다.
2. **가용성(Availability, A)**
   - 일부 노드에 장애가 발생하더라도 클라이언트는 항상 응답을 받을 수 있어야 한다.
3. **파티션 감내(Partition Tolerance, P)**
   - 네트워크 장애로 인해 노드 간 통신이 불가능해지더라도 시스템이 계속 동작해야 한다.

---

# 시스템 컴포넌트

## 데이터 파티션

대규모 서비스를 운영할 경우, **모든 데이터를 하나의 서버에 저장하는 것은 불가능**하다.  
이를 해결하기 위해 **데이터를 여러 개의 파티션으로 나누어** 여러 서버에 저장하는 방식을 사용한다.

### 데이터 파티션 시 고려할 문제점
1. 데이터를 여러 서버에 **고르게 분산**할 수 있는가?
2. 노드가 **추가되거나 삭제될 때 데이터 이동을 최소화**할 수 있는가?

이를 해결하기 위해 **안정 해시(Consistent Hashing)** 를 이용할 수 있다.

### 안정 해시를 이용한 데이터 파티션의 장점
1. **규모 확장 자동화**
   - 시스템 부하에 따라 서버가 자동으로 추가되거나 삭제될 수 있음.
2. **다양성**
   - 각 서버의 용량에 맞게 **가상 노드(Virtual Node)** 수를 조정 가능.
   - 고성능 서버는 더 많은 가상 노드를 가질 수 있음.

---

## 데이터 다중화

높은 **가용성과 안정성**을 보장하려면 **데이터를 N개 서버에 비동기적으로 다중화(Replication)** 해야 한다.

### 데이터 다중화 방식
- 특정 키를 해시 링에 배치한 후, **시계 방향으로 링을 순회하면서 N개의 서버에 데이터 사본을 저장**.

---

## 데이터 일관성

여러 노드에 다중화된 데이터는 **일관성 유지가 중요**하다.  
이를 위해 **정족수 합의(Quorum Consensus) 프로토콜**을 사용한다.

### 정족수(Quorum) 개념
- **N** = 사본 개수
- **W** = 쓰기 연산 정족수 (최소 W개의 서버에서 쓰기 성공해야 함)
- **R** = 읽기 연산 정족수 (최소 R개의 서버에서 읽기 성공해야 함)

### 정족수 설정 전략
- `R = 1, W = N` → **빠른 읽기 연산 최적화**
- `W = 1, R = N` → **빠른 쓰기 연산 최적화**
- `W + R > N` → **강한 일관성 보장**
- `W + R < N` → **일관성 보장되지 않음**

---

## 일관성 모델

일관성 수준에 따라 여러 가지 모델이 존재한다.

1. **강한 일관성(Strong Consistency)**
   - 모든 읽기 연산이 **가장 최근에 갱신된 결과**를 반환.
2. **약한 일관성(Weak Consistency)**
   - 읽기 연산이 최근 변경 내용을 보장하지 않음.
3. **결과적 일관성(Eventual Consistency)**
   - 시간이 지나면 모든 사본이 동일한 데이터를 가지게 됨.

### 강한 일관성 구현 방법
- **모든 사본에 쓰기 연산 결과가 반영될 때까지 읽기/쓰기 차단**.

---

## 비일관성 해소 기법: 데이터 버저닝

데이터 다중화는 **가용성을 높이는 대신, 사본 간 일관성을 깨뜨릴 위험**이 있다.  
이를 해결하기 위해 **버저닝(Versioning) 및 벡터 시계(Vector Clock)** 개념이 사용된다.

### 벡터 시계(Vector Clock)
- 데이터를 변경할 때마다 **서버별 버전 정보**를 저장.
- `Data[서버 인덱스, 버전]` 형태로 관리.

### 벡터 시계의 단점
1. 클라이언트가 **충돌 감지 및 해결 로직을 직접 구현해야 함**.
2. **버전 정보가 기하급수적으로 증가**할 수 있음.

---

# 장애 처리

## 장애 감지: 가십 프로토콜(Gossip Protocol)

- 각 노드는 **멤버십 목록**을 유지하며, 주기적으로 자신의 상태를 업데이트.
- 다른 노드들에게 **랜덤하게 상태 정보를 전파**.
- 일정 시간 동안 응답이 없으면 **해당 노드를 장애로 판단**.

---

## 반 엔트로피 프로토콜(Anti-Entropy Protocol)

분산 시스템에서 **데이터 사본 간 일관성을 유지하기 위한 동기화 프로토콜**.

- **사본 간 데이터 비교 → 최신 버전으로 업데이트**.
- 동기화 비용을 줄이기 위해 **머클 트리(Merkle Tree)** 사용.

### 머클 트리(Merkle Tree)
- **각 노드에 자식 노드들의 해시 값을 저장하는 구조**.
- 변경된 데이터만 탐지하여 **최소한의 데이터만 동기화** 가능.

---

# 데이터 저장 및 조회

## 쓰기 경로

1. **쓰기 요청이 커밋 로그에 기록됨**.
2. **데이터가 메모리 캐시에 저장됨**.
3. **캐시가 가득 차거나 일정 임계치 도달 시 SSTable에 기록됨**.

### SSTable (Sorted String Table)
- **정렬된 키-값 저장 구조**.
- LevelDB, Cassandra 등에서 사용되는 **LSM-Tree 기반 저장소**.

---

## 읽기 경로

1. **데이터가 메모리에 있는지 확인**.
2. **블룸 필터(Bloom Filter)를 사용해 SSTable을 탐색**.
3. **SSTable에서 데이터를 가져와 반환**.

### 블룸 필터(Bloom Filter)
- **"해당 데이터가 없음"을 100% 확신할 수 있지만, "있음"에는 오차 가능성 존재**.
- 여러 해시 함수를 사용하여 비트 배열을 업데이트.

예시)  
`Hash1("apple") → [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0]`  
→ 인덱스 `3, 7, 12`에 `1`이 설정됨.

