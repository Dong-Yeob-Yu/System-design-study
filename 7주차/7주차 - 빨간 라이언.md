# 개략적 설계

## 데이터 수집 사이즈

- 검색이 진행될때 마다 해당 질의의 내용에 빈도수를 저장한다. twitter 를 검색하면 twitter에 대한 빈도수가 1로 저장되는것이다.

```sql
SELECT *
FROM FREQUENCY_TABLE
WHERE QUERY LIKE $prefix
ORDER BY FREQUENCY DESC
LIMIT 5
```

- 이 같은 쿼리로 가장 많이 사용된 검색어 top5를 구할 수있다.
- 해당 로직은 데이터 양이 적을 때는 나쁘지 않은 설계안이다. 하지만 데이터가 많아지면 데이터 베이스가 병목될 수 있고 정렬문제, Full Scan, QPS(Query Per Second)를 크게 증가시킬 위험이 있다.

# 상세 설계

## 트라이(trie) 자료구조

### 트라이 자료구조

- 트라이는 트리 형태의 자료구조다.
- 이 트리의 루트 노드는 빈 문자열을 나타낸다.
- 각 노드는 글자 하나를 저장하며, 26개의 자식 노드를 가질 수 있다.
- 각 트리 노드는 하나의 단어, 또는 접두어 문자열을 나타낸다.

![](https://github.com/sangminlee98/system-design-interview/assets/83197138/9fc336d7-36dd-4612-afe1-7d9213f3aee0)

- 가장 많이 사용된 질의어 k개는 다음과 같이 찾을 수 있다.
    - 해당 접두어를 표현하는 노드를 찾는다. 시간 복잡도는 O(p) 이다.
    - 해당 노드부터 시작하는 하위트리를 탐색하여 모든 유효 노드를 찾는다. 유효한 검색 문자열을 구성하는 노드가 유효 노드다. 시간 복잡도는 O(c) 이다.
    - 유효 노드들을 정렬하여 가장 인기 있는 검색어 k개를 찾는다. 시간 복잡도는 O(clogc) 이다.

- k=2 이고 검색창에 be를 검색했을때 알고리즘 동작 흐름

![](https://github.com/sangminlee98/system-design-interview/assets/83197138/5d5b4f50-6b2d-4842-bab0-ea5f8466e29f)

1. 접두어 노드 ‘be’ 를 찾는다.
2. 해당 노드부터 싲가하는 하위 트리를 탐색하여 모든 유효 노드를 찾는다.
3. 유효 노드를 정렬하여 2개만 골라낸다. [best: 35], [bet: 29]접두어 tr에 대해 검색된 2개의 인기 검색어이다.
- 이 알고리즘의 시간 복잡도는 위의 각 단계에 소요된 시간의 합이다. 즉 O(p) + O(c) + O(clogc)
- 이 알고리즘은 직관적이지만 최악의 경우에는 k개 결과를 얻으려고 전체 트라이를 다 검색해야 하는 일이 생길 수 있다. 이 문제를 해결할 방법으로는 다음의 두 가지가 있다.
1. 접두어의 최대 길이를 제한
2. 각 노드에 인기 검색어를 캐시

### 접두어 최대 길이 제한

- 사용자가 검색창에 긴 검색어를 입력하는 일은 거의 없다. 따라서 p값은 작은 정숫값이라고 가정해도 안전하다. 검색어의 최대 길이를 제한할 수 있다면 “접두어 노드를 찾는” 단계의 시간 복잡도는 O(p) 에서 O(작은 상숫값)=O(1) 로 바뀔 것이다.

### 노드에 인기 검색어 캐시

![](https://github.com/sangminlee98/system-design-interview/assets/83197138/a4349c00-1359-418f-ab19-16cb12b8db0e)
각 노드에 인기 질의어를 캐시하면 top5 검색어를 질의하는 시간 복잡도를 엄청나게 낮출 수 있다. 하지만 각 노드에 질의어를 저장할 공간이 많이 필요하게 된다는 단점이 있다. 그러나 빠른 응답속도가 아주 중요할 때는 이 정도 저장공간을 희생할 만한 가치는 있다.

1. 접수어 노드를 찾는 시간 복잡도는 O(1)로 바뀐다.
2. 최고 인기 검색어 5개를 찾는 질의의 시간 복잡도도 O(1)로 바뀐다. 검색 결과가 이미 캐시되어 있어서다.

## 데이터 수집 서비스

- 지금까지 살펴본 설계안은 사용자가 검색창에 뭔가 타이핑을 할 때마다 실시간으로 데이터를 수정했는데 이러한 방식은 실용적이지 못하다.
    - 매일 수천만 건의 질의가 입력될 텐데 그때마다 트라이를 갱신하면 질의 서비스는 심각하게 느려질 것이다.
    - 일단 트라이가 만들어지고 나면 인기 검색어는 그다지 자주 바뀌지 않을 것이다. 그러니 트라이는 그렇게 자주 갱신할 필요가 없다.

![](https://github.com/sangminlee98/system-design-interview/assets/83197138/e613c44e-ff25-4285-b1c2-c19f3d77288d)

### 데이터 분석 서비스 로그

- 검색창에 입력된 질의에 관한 원본 데이터가 보관된다. 수정은 이루어지지않으며 새로운 데이터만 추가된다.

### 로그 취합 서버

- 데이터 분석 서비스로부터 나오는 로그는 데이터도 방대하고 형식도 제각각이다. 따라서 이 데이터를 잘 취합하여 우리 시스템이 쉽게 소비할 수 있도록 해야한다.
- 실시간이 중요하면 데이터 취합 주기를 짧게 가져갈 필요가 있고 대부분의 경우에는 일주일에 한 번 정도로 로그를 취합해도 충분하다.

### 취합된 데이터

![](https://github.com/sangminlee98/system-design-interview/assets/83197138/b9a7315e-e9e6-462c-84d7-586da9982e43)

- time은 해당 주가 시작한 날짜, frequency 필드는 해당 중 사용된 횟수의 합이다.

### 작업 서버

- 작업 서버는 주기적으로 비동기적 작업을 실행하는 서버 집합이다. 트라이 자료구조를 만들고 트라이 데이터베이스에 저장하는 역할을 담당한다.

### 트라이 캐시

- 트라이 캐시는 분산 캐시 시스템으로 트라이 데이터를 메모리에 유지하여 읽기 연산 성능을 높이는 구실을 한다. 매주 트라이 데이터베이스의 스냅샷을 떠서 갱신한다.

### 트라이 데이터베이스

- 트라이 데이터베이스는 지속성 저장소다. 트라이 데이터베이스로 사용할 수 있는 선택지로는 다음의 2가지가 있다.
    1. 문서 저장소 : 새 트라이를 매주 만들 것으므로, 주기적으로 트라이를 직렬화하여 DB에 저장할 수 있다. 몽고디비 같은 문서 저장소를 활용하면 이런 데이터를 편리하게 저장할 수 있다.
    2. 키-값 저장소 : 트라이는 아래 로직을 적용하면 해시 테이블 형태로 변환 가능하다.
        - 트라이에 보관된 모든 접두어를 해시 테이블 키로 변환
        - 각 트라이 노드에 보관된 모든 데이터를 해시 테이블 값으로 변환

## 질의 서비스

![](https://github.com/sangminlee98/system-design-interview/assets/83197138/fe954ee6-7139-4f0e-92ad-6337e4afb121)

1. 검색 질의가 로드밸런서로 전송된다.
2. 로드밸런서는 해당 질의를 API 서버로 보낸다.
3. API 서버는 트라이 캐시에서 데이터를 가져와 해당 요청에 대한 자동완성 검색어 제안 응답을 구성한다.
4. 데이터가 트라이 캐시에 없는 경우에는 데이터를 DB에서 가져와 캐시에 채운다. 그래야 다음에 같은 접두어에 대한 질의가 오면 캐시에 보관된 데이터를 사용해 처리할 수 있다. 캐시 미스는 캐시 서버의 메모리가 부족하거나 캐시 서버에 장애가 있어도 발생할 수 있다.

최적화 방안

- AJAX 요청
- 브라우저 캐싱
- 데이터 샘플링 : N개 요청 가운데 1개만 로깅하도록 한다.

## 트라이 연산

### 트라이 생성

- 트라이 생성은 작업 서버가 담당하며, 데이터 분석 서비스의 로그나 DB로부터 취합된 데이터를 이용한다.

### 트라이 갱신

- 트라이를 갱신하는 방법은 2개가 있다.
    1. 매주 한 번 갱신하는 방법. 새로운 트라이를 만든 다음에 기존 트라이를 대체한다.
    2. 트라이의 각 노드를 개별적으로 갱신하는 방법. 본 설계안에선 채택안했는데 성능이 좋지 않아서다. 하지만 트라이가 작을 때는 고려해봄직한 방안이다.

### 검색어 삭제

- 혐오성이 짙거나, 폭력적이거나 여러 가지로 위험한 질의어를 자동완성 결과에서 제거해야 한다. 이를 위한 좋은 방법은 API 서버와 트라이 캐시 앞에 필터 계층 을 두고 부적절한 질의어가 반환되지 않도록 하는 것이다. 필터 계층을 두면 필터 규칙에 따라 검색 결과를 자유롭게 변경할 수 있다는 장점이 있다. DB에서 해당 검색어를 물리적으로 삭제하는 것은 다음번 업데이트 사이클에 비동기적으로 진행하면 된다.

### 저장소 규모 확장

- 본 요구사항은 영어만 지원하면 되기 때문에 첫 글자를 기준으로 샤딩 하는 방법을 생각해 볼 수 있다.
    - 검색어를 보관하기 위해 두 대 서버가 필요하다면 ‘a’부터 ‘m’까지 글자로 시작하는 검색어는 첫 번재 서버에 저장하고 나머지는 두 번째 서버에 저장 한다.
    - 세 대 서버가 필요하다면 ‘a’ ~ ‘i’ 까지 첫번째 서버, ‘j’~’r’ 까지는 두번째 서버, 나머지는 세 번째 서버에 저장한다.
- 이 방법을 쓰는 경우 사용 가능한 서버는 최대 26대로 제한되는데, 영어 알파뱃은 26자 밖에 없기 때문이다. 이 이상으로 서버를 늘릴려면 계층적으로 해야한다.
- 위의 방법은 데이터를 각 서버에 균등하게 배분하기는 불가능하다. 본 설계안에선 과거 질의 데이터의 패턴을 분석하여 샤딩하는 방법을 제안한다. 이 그림에서 검색어 대응 샤드 관리자는 어떤 검색어가 어느 저장소 서버에 저장되는지에 대한 정보를 관리한다.

# 마무리

- 다국어 지원 : 비영어권 국가에서 사용하는 언어를 지원하려면 트라이에 유니코드 데이터를 저장해야한다.
- 국가별로 인기 순위 : 국가별로 다른 트라이를 사용하면 된다. 트라이를 CDN에 저장하여 응답속도를 높이는 방법도 생각해볼 수 있다.
- 실시간 검색어 반영 : 현재 설계안은 그런 검색어를 지원하기에 적합하지 않다. 이유는 다음과 같다.
    - 작업 서버가 매주 한 번씩만 돌도록 되어 있어서 시의 적절하게 트라이를 갱신할 수 없다.
    - 설사 때맞춰 서버가 실행된다 해도, 트라이를 구성하는 데 너무 많은 시간이 소요된다.